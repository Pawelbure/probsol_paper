\documentclass[D:/studies/WinnerS/Erhebungen/IPhO1718/paper/probsol_paper/main/TaylorFrancis/interactapasample]{subfiles}

%\usepackage{Sweave}

\begin{document}
\SweaveOpts{concordance=F, echo = F, results = tex}


<<>>=
where <- "work"
if( where=="home" ){
  dir <- "D:/studies/WinnerS/Erhebungen/IPhO1718/"
} else {
  dir <- "C:/Users/Peter/Desktop/winners/IPhO1718/"
}

setwd( paste0( dir, "paper/probsol_paper/results/" ) )

library(tables)
library(psych)
library(xtable)
library(ggplot2)
library(BasicFunctions)
library(car)
library(pastecs)
library(rstan)
library(openxlsx)
library(VGAM)

load( paste0( dir, "/data/clean/data.RData") )
load( paste0( dir, "/codebook/scales.RData") )
cb <- read.xlsx( paste0( dir, "/codebook/codebook.xlsx" ) )

# reallocate imputed to normal scale:
d$apt.c.2 <- d$apt.c.imp.2

# necessary variables:
# vars <- c("apt.c.2","mcphy.c.2","probSol.c.2","achievR1.1","Quali","kft.c.imp.2","swk.phy.1","sob.1","expComp.1","valComp.1","Age.1")
vars <- c("probSol.c.2","apt.c.2","kft.c.imp.2",
          # "achievR1.1",
          "swk.phy.1","expComp.1","valComp.1","sob.1","ss.1","Quali","Age.1")

varsX <- gsub( "\\.2|\\.1", "", vars)
add <- ifelse( !substr( vars, nchar(vars)-1, nchar(vars) )%in%c(".1",".2"), "", substr( vars, nchar(vars)-1, nchar(vars) ) )


# ## adopt problem solving scale:
# attrx <- attributes( s$probSol.c )
# s$probSol.c <- grep("execution",s$probSol.c, value = T, invert = T)
# s$probSol.c <- grep("elko|loop",s$probSol.c, value = T, invert = F)
# attributes( s$probSol.c ) <- attrx
# 
# d$probSol.c.2 <- ifelse( apply( is.na( d[ ,paste0( s$probSol.c, ".2" ) ] ), 1, all ), NA,
#                          rowSums( d[ ,paste0( s$probSol.c, ".2" ) ], na.rm = T ) )


# only students that have all cognitive measures:
# df <- subset( d, Code%in%na.omit( d[,c("Code",vars)] )$Code )
df <- subset( d, Code%in%na.omit( d[,c("Code",vars[c(1)])] )$Code )
df <- subset( df, df$Quali!=4 )
@



\section{Results}
<<>>=
ctab <- corrTab(vars = vars, data = df, real.names = unlist( lapply( varsX, function(x) attr( s[[x]], "name" ) ) ), with.means = F )
@


Since the motivational variables are self-reported measures and the cognitive variables likely tap similar cognitive abilities, it is necessary to investigate the correlations among the variables first in order to verify that no multi-collinearity is present. The correlations (Table \ref{correlation_table}) show values in the range between $\Sexpr{paste0( round( range( cor( df[,vars], use = "pairwise.complete.obs" )[ upper.tri( cor( df[,vars], use = "pairwise.complete.obs" ) ) ] ), 2 ), collapse = "-" )}$. However, most values are lower such that no multicollinearity is present. One pattern in the correlation matrix is that the cognitive variables correlate significantly amongst each other and the motivational variables correlate significantly amongst each other in positive directions. Social support shows almost no significant correlation with another variable. Interestingly, self-efficacy in physics is not correlated with cognitive variables, which is quiet counter-intuitive given the literature on self-efficacy (see: Bandura, 1997). Expectancy of success in the competition, however, is significantly correlated with the cognitive variables, possibly because it is more context-specific such that students can better judge their actual ability.

\begin{sidewaystable}
\caption{Correlations among measured variables.}
\label{correlation_table}
<<>>=
print( xtable( ctab, align = paste0( c("ll",rep("c",ncol(ctab)-1)), collapse = "" ) ),
             booktabs = T, sanitize.text.function = function(x) x, include.rownames = F, floating = F )

@
\end{sidewaystable}



<<>>=
add <- ifelse( !substr( vars, nchar(vars)-1, nchar(vars) )%in%c(".1",".2"), "", substr( vars, nchar(vars)-1, nchar(vars) ) )

# scaling variables:
df <- cbind( df[ , c( vars[ vars%in%c("achievR1.1","Quali") ], "Code", "Geschlecht.1" ) ],
             apply( df[ ,vars[ !vars%in%c("achievR1.1","Quali") ] ], 2, scale ) )

# # ANOVA:
# anova.fit <- summary( lm( probSol.c.2 ~ factor( Quali ), data = df ))
# pairwise.t.test(df$probSol.c.2, df$Quali, p.adj = "bonf")

# # test for equal variance (equal variance assumption holds):
# aggregate( probSol.c.2 ~ factor( Quali ), data = df, FUN = var )
# leveneTest( probSol.c.2 ~ factor( Quali ), data = df )


########################
# ordinal regression:
fitA <- vglm( Quali ~ probSol.c.2 + apt.c.2 + kft.c.imp.2, data = df, family = cumulative(parallel=T, reverse = T, link = "logit"))
fitB <- vglm( Quali ~ probSol.c.2 + apt.c.2 + kft.c.imp.2, data = df, family = cumulative(parallel=F, reverse = T, link = "logit"))

# # testing for distributional problems (see Winship et al., 1984, p. 519)
# subd <- df
# subd$test <- subd$apt.c.2 + subd$probSol.c.2
# subd$X <- ifelse( subd$test>median(subd$test), 1, 0 )
# 
# fita <- vglm( Quali ~ apt.c.2 + probSol.c.2, data = subd, family = cumulative(parallel=T, reverse = T))
# fitb <- vglm( Quali ~ apt.c.2*X + probSol.c.2*X, data = subd, family = cumulative(parallel=T, reverse = T))
# distri.test <- lrtest(fita,fitb) # no apparent problems with distribution


## test for parallel slopes assumption
parallel.slopes <- lrtest(fitA,fitB)

#R^2 Nagelkerke
p0 <- vglm(Quali ~ 1, data = df, family = propodds)
p0.ll <- logLik(p0)
N <- length(df[, 1])
pFull.ll <- logLik(fitA)
R2.nagel <- as.vector((1 - exp((2/N) * (p0.ll - pFull.ll)))/(1 - exp(p0.ll)^(2/N)))
# R2.nagel

# create output table
tab2 <- data.frame( coefficients( summary(fitA) ), check.names = F )
tab2$OR <- exp( tab2[,1] )
tab2 <- round( tab2, 2 )
row.names(tab2)[ match( c("apt.c.2","probSol.c.2"), row.names(tab2) ) ] <- substitute.names( row.names(tab2)[ match( c("apt.c.2","probSol.c.2"), row.names(tab2) ) ], substitute_codes = data.frame( code = c( cb$scale, "kft.c.imp.2"), name = c(cb$scale.c.short, "Cog. abilities" ) ), delete = c(".1",".2"), codebk.there = F )
row.names(tab2) <- paste0( row.names(tab2), " " )
tab3 <- matrix( "", ncol = 5, nrow = 2 )
row.names(tab3) <- c("","$R^2_{\\text{adj}}$")
tab3[2,1] <- round( R2.nagel, 2 )
colnames(tab3) <- colnames(tab2)

tab2 <- rbind( tab2, tab3 )
tab2 <- tab2[-c(1:max(grep("Intercept",rownames(tab2)))),]
colnames(tab2) <- c("$\\beta$","$SE(\\beta)$","$z$","$p$","$OR$")
tab2$`$p$` <- give.star( as.numeric( tab2$`$p$` ), modus = "semi.text" )


#############################################
# with covariates:
# vars <- c("apt.c.2","probSol.c.2","Quali","kft.c.imp.2","swk.phy.1","sob.1","expComp.1","valComp.1","Age.1","Geschlecht.1")
form1 <- paste0( vars[ !vars%in%c("Quali") ], collapse = " + " )
fitC <- vglm( as.formula( paste0( "Quali ~", form1 ) ) , data = df, family = cumulative(parallel=T, reverse = T, link = "logit" ))

# # logistische Regression:
# df$QualiR2.1 <- d$QualiR2.1[ match( df$Code, d$Code ) ]
# fit.logist <- glm( as.formula( paste0( "QualiR2.1 ~", form1 ) ) , data = df, family = binomial(link="logit") )
# summary( fit.logist )
# 
# logreg <- function(x) exp(x)/(1+exp(x))
# ggplot( df, aes(x=probSol.c.2, y=jitter(QualiR2.1))) + geom_point() + stat_function( fun = )


# create output table:
tab4 <- data.frame( coefficients( summary(fitC) ), check.names = F )
tab4$OR <- exp( tab4[,1] )
tab4 <- round( tab4, 2 )
# delete intercepts:
tab4 <- tab4[-c(1:max(grep("Intercept",rownames(tab4)))),]

# make nice row names:
row.names(tab4) <- substitute.names( row.names(tab4), substitute_codes = 
                                 data.frame( code = c( cb$scale, "kft.c.imp","Geschlechtw"), 
                                             name = c(cb$scale.c.short, "Cog. abilities","Gender (f)" ) ), 
                                     delete = c(".1",".2"), codebk.there = F )

#R^2 Nagelkerke
pFull.ll.2 <- logLik(fitC)
R2.nagel.2 <- as.vector((1 - exp((2/N) * (p0.ll - pFull.ll.2)))/(1 - exp(p0.ll)^(2/N)))
# R2.nagel


tab5 <- matrix( "", ncol = 5, nrow = 2 )
row.names(tab5) <- c("","$R^2_{\\text{adj}}$")
tab5[2,1] <- round( R2.nagel.2, 2 )
colnames(tab5) <- colnames(tab4)

tab4 <- rbind( tab4, tab5 )
colnames(tab4) <- c("$\\beta$","$SE(\\beta)$","$z$","$p$","$OR$")
tab4$`$p$` <- give.star( as.numeric( tab4$`$p$` ), modus = "semi.text" )

tab2 <- rbind( tab2, tab4 )

# adjust names a little..
row.names( tab2 )[6] <- paste0( "\\midrule ", row.names( tab2 )[6])
row.names( tab2 )[c(nrow(tab2)-1,nrow(tab2))] <- gsub( "1"," ",row.names( tab2 )[c(nrow(tab2)-1,nrow(tab2))] )
@

In order to characterize successful particupants (RQ 1), generalized linear models that account for the ordinal metric of the dependent variable are utilized. Cognitive and motivational variables are included as predictors for highest qualified round (dependent variable). Achievement in round 1 in the physics Olympiad was omitted as a cognitive variable because of the high correlation with the other cognitive measures that were of more interest to us. Proportional odds models were used in order to predict success in the Physics Olympiad in a hierarchical regression procedure (Field, 2012). First, cognitive variables were included as predictors in the model because these predictors can be considered most important for characterizing successful students in the Physics Olympiad based on prior research. In a second step, cognitive variables and motivational variables were jointly entered in the model.

Generalized linear models, as any mathematical model, come with certain assumptions that need be tested prior to conducting the analysis. The modelling assumption of parallel slopes holds in our case, \Sexpr{paste0( "$\\\\chi^2=", round( parallel.slopes@Body$Chisq[2], 2 ), ", p=", gsub( "\\$", "", give.star( parallel.slopes@Body$`Pr(>Chisq)`[2], modus = "semi.text" ) ), "$" )}. 

The interesting parameters in the model are the effects (not the intercepts). The effects can be interpreted in accordance with the regression parameters in linear regression (B\"u{}rkner \& Vuorre, 2018). Table \ref{propOddModel} shows the results from the analysis. As can be expected, physics problem conceptualization and generic physics problem solving are significantly positively related with highest qualified round of the participants. The relationship holds when entering the motivational variables to the model. When all variables are included in the model, expectancy of success in the competition shows a significant positive relationship with highest qualified round as well. No other effects become significant and thus characterize successful students in this study. Physics problem conceptualization has the highest odds ratio, and thus a change in physics problem conceptualization of one standard deviation has the highest contribution to the likelihood of a student to reach a higher round. In order to graphically represent this relationship, Figure \ref{problem_concept_skills} depicts highest round over physics problem conceptualization skills.


\begin{table}
\caption{Proportional odds model for predicting highest qualified round in the physics Olympiad with various predictors.}
\label{propOddModel}
<<>>=
print( xtable( tab2, align = paste0( c("ll",rep("c",ncol(tab2)-1)), collapse = "" ) ),
             booktabs = T, sanitize.text.function = function(x) x, include.rownames = T, only.contents = F, floating = F )
@
\end{table}


<<>>=
# tikzDevice::tikz(file = "img/boxplot.tex", width = 5, height = 3)
# ggplot( df, aes(x=factor( Quali ),y=probSol.c.2 ) ) + geom_boxplot() +
#   geom_jitter(shape=16, position=position_jitter(0.2)) + theme_bw() + ylab("Problem comprehension") + xlab("Highest round") #+ coord_flip()
# invisible( dev.off() )
@

\begin{figure}
\centering
% \includegraphics[width=.7\textwidth]{D:/studies/WinnerS/Erhebungen/IPhO1718/paper/problem_solving/results/ordinal_regression/img/boxplot}
\input{D:/studies/WinnerS/Erhebungen/IPhO1718/paper/problem_solving/results/img/boxplot}
\caption{Problem conceptualization scores over highest achieved round of participant.}
\label{problem_concept_skills}
\end{figure}

\end{document}
